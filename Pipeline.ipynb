{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7faafe9d-d9ee-42d4-aa52-d9c2e5c4be82",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-riva-client in /opt/conda/lib/python3.10/site-packages (0.0.5)\n",
      "Requirement already satisfied: grpcio-tools in /opt/conda/lib/python3.10/site-packages (from nvidia-riva-client) (1.50.0)\n",
      "Collecting grpcio>=1.50.0\n",
      "  Using cached grpcio-1.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from grpcio-tools->nvidia-riva-client) (65.5.0)\n",
      "Collecting protobuf<5.0dev,>=4.21.6\n",
      "  Using cached protobuf-4.21.9-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio>=1.50.0->grpcio-tools->nvidia-riva-client) (1.16.0)\n",
      "Installing collected packages: protobuf, grpcio\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.41.0\n",
      "    Uninstalling grpcio-1.41.0:\n",
      "      Successfully uninstalled grpcio-1.41.0\n",
      "Successfully installed grpcio-1.50.0 protobuf-4.21.9\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.4)\n",
      "Requirement already satisfied: tritonclient[all] in /opt/conda/lib/python3.10/site-packages (2.27.0)\n",
      "Requirement already satisfied: numpy>=1.19.1 in /opt/conda/lib/python3.10/site-packages (from tritonclient[all]) (1.23.4)\n",
      "Requirement already satisfied: python-rapidjson>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from tritonclient[all]) (1.9)\n",
      "Collecting protobuf<3.20,>=3.5.0\n",
      "  Using cached protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: aiohttp>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from tritonclient[all]) (3.8.3)\n",
      "Requirement already satisfied: geventhttpclient<=2.0.2,>=1.4.4 in /opt/conda/lib/python3.10/site-packages (from tritonclient[all]) (2.0.2)\n",
      "Collecting grpcio==1.41.0\n",
      "  Using cached grpcio-1.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio==1.41.0->tritonclient[all]) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (2.1.1)\n",
      "Requirement already satisfied: gevent>=0.13 in /opt/conda/lib/python3.10/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (22.10.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (2022.9.24)\n",
      "Requirement already satisfied: brotli in /opt/conda/lib/python3.10/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (1.0.9)\n",
      "Requirement already satisfied: greenlet>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (2.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (65.5.0)\n",
      "Requirement already satisfied: zope.interface in /opt/conda/lib/python3.10/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (5.5.1)\n",
      "Requirement already satisfied: zope.event in /opt/conda/lib/python3.10/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (4.5.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.8.1->tritonclient[all]) (3.4)\n",
      "Installing collected packages: protobuf, grpcio\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.9\n",
      "    Uninstalling protobuf-4.21.9:\n",
      "      Successfully uninstalled protobuf-4.21.9\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.50.0\n",
      "    Uninstalling grpcio-1.50.0:\n",
      "      Successfully uninstalled grpcio-1.50.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-tools 1.50.0 requires grpcio>=1.50.0, but you have grpcio 1.41.0 which is incompatible.\n",
      "grpcio-tools 1.50.0 requires protobuf<5.0dev,>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed grpcio-1.41.0 protobuf-3.19.6\n"
     ]
    }
   ],
   "source": [
    "!pip install nvidia-riva-client\n",
    "!pip install numpy\n",
    "!pip install tritonclient[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f99b7a-cdf8-4f1e-a3e2-cbbffb402a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import riva.client\n",
    "auth = riva.client.Auth(uri='10.100.182.246:50051')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5247ce-a8db-4ac1-ac95-ea9678422229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tritonclient.http as httpclient\n",
    "\n",
    "from tritonclient.utils import np_to_triton_dtype\n",
    "\n",
    "URL = \"10.98.96.143:8000\"\n",
    "MODEl_GPTJ_FASTERTRANSFORMER = \"ensemble\" \n",
    "\n",
    "OUTPUT_LEN = 128\n",
    "BATCH_SIZE = 1\n",
    "BEAM_WIDTH = 1\n",
    "TOP_K = 1\n",
    "TOP_P = 0.0\n",
    "\n",
    "start_id = 220\n",
    "end_id = 50256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a70d50-0420-4114-9e04-74388ec3f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = httpclient.InferenceServerClient(URL,\n",
    "                                           concurrency=1,\n",
    "                                           verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98dee164-ca6c-4a87-8b10-246f7b19cedc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'triton',\n",
       " 'version': '2.18.0',\n",
       " 'extensions': ['classification',\n",
       "  'sequence',\n",
       "  'model_repository',\n",
       "  'model_repository(unload_dependents)',\n",
       "  'schedule_policy',\n",
       "  'model_configuration',\n",
       "  'system_shared_memory',\n",
       "  'cuda_shared_memory',\n",
       "  'binary_tensor_data',\n",
       "  'statistics']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_server_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b592acc5-62ad-4d28-8d6f-f58a4db8431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference hyperparameters\n",
    "def prepare_tensor(name, input):\n",
    "    tensor = httpclient.InferInput(\n",
    "        name, input.shape, np_to_triton_dtype(input.dtype))\n",
    "    tensor.set_data_from_numpy(input)\n",
    "    return tensor\n",
    "\n",
    "# explanation\n",
    "def prepare_inputs(input0):\n",
    "    bad_words_list = np.array([[\"\"]], dtype=object)\n",
    "    stop_words_list = np.array([[\"\"]], dtype=object)\n",
    "    input0_data = np.array(input0).astype(object)\n",
    "    output0_len = np.ones_like(input0).astype(np.uint32) * OUTPUT_LEN\n",
    "    runtime_top_k = (TOP_K * np.ones([input0_data.shape[0], 1])).astype(np.uint32)\n",
    "    runtime_top_p = TOP_P * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    beam_search_diversity_rate = 0.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    temperature = 1.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    len_penalty = 1.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    repetition_penalty = 1.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    random_seed = 0 * np.ones([input0_data.shape[0], 1]).astype(np.int32)\n",
    "    is_return_log_probs = True * np.ones([input0_data.shape[0], 1]).astype(bool)\n",
    "    beam_width = (BEAM_WIDTH * np.ones([input0_data.shape[0], 1])).astype(np.uint32)\n",
    "    start_ids = start_id * np.ones([input0_data.shape[0], 1]).astype(np.uint32)\n",
    "    end_ids = end_id * np.ones([input0_data.shape[0], 1]).astype(np.uint32)\n",
    "\n",
    "    inputs = [\n",
    "        prepare_tensor(\"INPUT_0\", input0_data),\n",
    "        prepare_tensor(\"INPUT_1\", output0_len),\n",
    "        prepare_tensor(\"INPUT_2\", bad_words_list),\n",
    "        prepare_tensor(\"INPUT_3\", stop_words_list),\n",
    "        prepare_tensor(\"runtime_top_k\", runtime_top_k),\n",
    "        prepare_tensor(\"runtime_top_p\", runtime_top_p),\n",
    "        prepare_tensor(\"beam_search_diversity_rate\", beam_search_diversity_rate),\n",
    "        prepare_tensor(\"temperature\", temperature),\n",
    "        prepare_tensor(\"len_penalty\", len_penalty),\n",
    "        prepare_tensor(\"repetition_penalty\", repetition_penalty),\n",
    "        prepare_tensor(\"random_seed\", random_seed),\n",
    "        prepare_tensor(\"is_return_log_probs\", is_return_log_probs),\n",
    "        prepare_tensor(\"beam_width\", beam_width),\n",
    "        prepare_tensor(\"start_id\", start_ids),\n",
    "        prepare_tensor(\"end_id\", end_ids),\n",
    "    ]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "805704b5-e340-4439-9b99-967b48bab2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_user = (\n",
    "    \"Polish: Gdzie jest najbliższa stacja kolejowa? \\n\"\n",
    "    \"English: Where is the nearest train station? \\n\\n\"\n",
    "    \"Polish: Ile kosztuje bilet kolejowy do Warszawy? \\n\"\n",
    "    \"English: How much is a train ticket to Warsaw? \\n\\n\"\n",
    "    \"Polish: Niestety nie mówię po Francusku. \\n\"\n",
    "    \"English: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5aaa88a-9507-44e1-9f5d-92d9121a1ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_user = (\n",
    "    \"French: Il n'est guère nécessaire d'insister sur l'importance de l'étude de \"\n",
    "\"Mythologie : nos poèmes, nos romans et même nos journaux quotidiens regorgent de \"\n",
    "\"allusions classiques; une visite dans nos galeries d'art et nos musées ne peut pas non plus être \"\n",
    "\"pleinement apprécié sans quelque chose de plus qu'une simple connaissance superficielle d'un \"\n",
    "\"sujet qui a de tout temps inspiré peintres, sculpteurs et poètes. Ce \"\n",
    "\"il ne me reste donc plus qu'à exprimer l'espoir que mon petit travail pourra \"\n",
    "\"s'avérer utile, non seulement pour les enseignants et les universitaires, mais aussi pour une classe nombreuse \"\n",
    "\"de lecteurs généraux, qui, en passant une heure de loisir, peuvent en tirer \"\n",
    "\"plaisir et profiter de sa lecture. \\n\"\n",
    "\"English: It is hardly necessary to dwell upon the importance of the study of \"\n",
    "\"Mythology: our poems, our novels, and even our daily journals teem with \"\n",
    "\"classical allusions; nor can a visit to our art galleries and museums be \"\n",
    "\"fully enjoyed without something more than a mere superficial knowledge of a \"\n",
    "\"subject which has in all ages inspired painters, sculptors, and poets. It \"\n",
    "\"therefore only remains for me to express a hope that my little work may \"\n",
    "\"prove useful, not only to teachers and scholars, but also to a large class \"\n",
    "\"of general readers, who, in whiling away a leisure hour, may derive some \"\n",
    "\"pleasure and profit from its perusal. \\n\\n\"\n",
    "\"French: J'ajoute qu'aucun effort n'a été épargné pour que, sans passer \"\n",
    "\"sur des détails dont l'omission aurait {ii} entaché l'exhaustivité \"\n",
    "\"de l'œuvre, pas un seul passage ne doit être trouvé qui pourrait éventuellement \"\n",
    "\"offenser la délicatesse la plus scrupuleuse; et aussi que j'ai volontairement traité \"\n",
    "\"le sujet avec cette révérence que je considère due à tout religieux \"\n",
    "\"système, même erroné. \\n\"\n",
    "\"English: I may add that no pains have been spared in order that, without passing \"\n",
    "\"over details the omission of which would have {ii} marred the completeness \"\n",
    "\"of the work, not a single passage should be found which could possibly \"\n",
    "\"offend the most scrupulous delicacy; and also that I have purposely treated \"\n",
    "\"the subject with that reverence which I consider due to every religious \"\n",
    "\"system, however erroneous. \\n\\n\"\n",
    "\"French:  En m'efforçant de répondre à ce besoin, j'ai cherché à placer devant le \"\n",
    "\"lecteur une image réaliste des divinités de l'époque classique telles qu'elles étaient \"\n",
    "\"conçu et adoré par les anciens eux-mêmes, et ainsi réveiller\"\n",
    "\"dans l'esprit des jeunes étudiants un désir de devenir plus intime\"\n",
    "\"connaître les nobles productions de l'antiquité classique.\\n\"\n",
    "\"English: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccf6ba5a-e632-434f-91b5-71b16edbcdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_user = (\n",
    "        \"Before entering upon the many strange beliefs of the ancient Greeks, and \"\n",
    "\"the extraordinary number of gods they worshipped, we must first consider \"\n",
    "\"what kind of beings these divinities were. \\n \"\n",
    "    \" Prima di addentrarci nelle tante strane credenze degli antichi greci, e \"\n",
    "\"lo straordinario numero di dei che adoravano, dobbiamo prima considerare \"\n",
    "\"che tipo di esseri erano queste divinità. \\n\\n\"\n",
    "        \"They were also more \"\n",
    "\"commanding in stature, height being considered by the Greeks an attribute \"\n",
    "\"of beauty in man or woman. \\n \"\n",
    "    \"Erano anche di più \"\n",
    "\"di statura imponente, essendo l'altezza considerata dai Greci un attributo \"\n",
    "\"di bellezza nell'uomo o nella donna. \\n\\n\"\n",
    "    \"The Greeks believed that the mental qualifications of their gods were of a \"\n",
    "\"much higher order than those of men. \\n\"\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce866d56-fd34-4fbd-b21f-6b57586d2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input0 = [[input_user],]\n",
    "inputs = prepare_inputs(input0)\n",
    "result = client.infer(MODEl_GPTJ_FASTERTRANSFORMER, inputs)\n",
    "output0 = result.as_numpy(\"OUTPUT_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1bc9891c-1867-4f89-a7b8-08393bfa88db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Before entering upon the many strange beliefs of the ancient Greeks, and the extraordinary number of gods they worshipped, we must first consider what kind of beings these divinities were. \n",
      " Italian: Prima di addentrarci nelle tante strane credenze degli antichi greci, e lo straordinario numero di dei che adoravano, dobbiamo prima considerare che tipo di esseri erano queste divinità. \n",
      "\n",
      "English: They were also more commanding in stature, height being considered by the Greeks an attribute of beauty in man or woman. \n",
      " Italian: Erano anche di più di statura imponente, essendo l'altezza considerata dai Greci un attributo di bellezza nell'uomo o nella donna. \n",
      "\n",
      "English: The Greeks believed that the mental qualifications of their gods were of a much higher order than those of men. \n",
      "Italian: \n",
      " The Greeks believed that the mental qualifications of their gods were of a much higher order than those of men. \n",
      " Italian: I Greci credevano che le qualificazioni mentali delle loro divinità fossero di un ordine molto più elevato di quelli dell'uomo. \n",
      "\n",
      "Italian: \n",
      " The Greeks believed that the mental qualifications of their gods were of a much higher order than those of men. \n",
      " Italian: I Greci credevano che le qualificazioni mentali delle loro divinità fossero di un\n"
     ]
    }
   ],
   "source": [
    "print(output0[0].decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cc3c445-2499-48fa-96c4-aac2fab1b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_code = 'en-US'\n",
    "sample_rate_hz = 16000\n",
    "nchannels = 1\n",
    "sampwidth = 2\n",
    "text = (\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7491a5a-4423-4626-bcc3-d8c39d291363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They were also more commanding in stature, height being considered by the Greeks an attribute of beauty in man or woman. \n",
      " Erano anche di più di statura imponente, essendo l'altezza considerata dai Greci un attributo di bellezza nell'uomo o nella donna.  \n",
      "\n",
      "They were also more commanding in stature, height being considered by the Greeks an attribute of beauty in man or woman. \n",
      " Erano anche di più di statura imponente, essendo l'altezza considerata dai Greci un attributo di bellezza nell'uomo o nella donna.  \n",
      "\n",
      "They were also more commanding in stature, height being considered by the Greeks an attribute of beauty in man or woman. \n",
      " Erano anche di più di statura imponente, essendo l'altezza considerata dai Greci un attributo di bellezza nell'uomo o nella donna.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input0 = [[input_user],]\n",
    "inputs0 = prepare_inputs(input0)\n",
    "result = client.infer(MODEl_GPTJ_FASTERTRANSFORMER, inputs0)\n",
    "output0 = result.as_numpy(\"OUTPUT_0\")\n",
    "\n",
    "TOP_K = 0.3\n",
    "TOP_P = 0.8\n",
    "for p in input_user.split(\"\\n\\n\"):\n",
    "    input1 = [[p],]\n",
    "    inputs1 = prepare_inputs(input1)\n",
    "    result = client.infer(MODEl_GPTJ_FASTERTRANSFORMER, inputs1)\n",
    "    output1 = result.as_numpy(\"OUTPUT_0\")\n",
    "    strOut = output0[0].decode('UTF-8').split(\"\\n\\n\")\n",
    "    print(strOut[1], \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad5f1b-eca6-4cab-82c5-72ca07746fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
